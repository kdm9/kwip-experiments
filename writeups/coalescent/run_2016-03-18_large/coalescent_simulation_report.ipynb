{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of the Coalescent Simulation\n",
    "====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(plyr)\n",
    "library(reshape2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset\n",
    "-------\n",
    "\n",
    "This is the summary of Spearman's $\\rho$ over 10 replicates of the \"coalescent\" experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats = read.csv(\"overall.csv\")\n",
    "stats$rep = as.factor(sort(rep(1:10, times=28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare average genome coverage and the scale of varaition againsnt accuracy (i.e. Spearman's $\\rho$) (over the 10 reps).\n",
    "\n",
    "We compare the effects of coverage and scale independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coverage vs $\\rho$\n",
    "------------------\n",
    "\n",
    "A series of average coverages was run at the scale of 0.01 (i.e. an average of 1 variant in 100 bases across all pairwise comparisions of samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coverage = stats[stats$scale==0.01, ]\n",
    "coverage$scale = NULL\n",
    "summary(coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggplot(coverage, aes(x=coverage, y=spearman, linetype=measure, color=rep)) +\n",
    "    geom_line(aes(linetype=measure, color=rep),size=1.5) +\n",
    "    xlab('Genome Coverage') +\n",
    "    ylab(expression(paste(\"Spearman's \", rho))) +\n",
    "    #scale_x_log10()+\n",
    "    theme_bw() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we summarise the replicates to averages $\\pm$ SD. Note that we exclude replicate 8 as it is an outlier for both IP and WIP metrics (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coverage = coverage[coverage$rep != 8,]\n",
    "csumm = ddply(coverage, .(coverage, measure), summarise,\n",
    "                spearman_m=mean(spearman),\n",
    "                spearman_sd=sd(spearman))\n",
    "summary(csumm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see below that WIP marginally outperforms IP, at low coverage. Above about 20x, I would say that WIP and IP have equivalent performance.\n",
    "\n",
    "The ribbon is 1 SD, so there is certainly no signficant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggplot(csumm, aes(x=coverage, y=spearman_m, ymin=spearman_m-spearman_sd, ymax=spearman_m+spearman_sd, group=measure)) +\n",
    "    geom_line(aes(linetype=measure)) +\n",
    "    geom_ribbon(aes(fill=measure), alpha=0.2) +\n",
    "    xlab('Genome Coverage') +\n",
    "    ylab(expression(paste(\"Spearman's \", rho))) +\n",
    "    #scale_x_log10()+\n",
    "    theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differnce between WIP and IP is calculated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdiff = dcast(coverage, coverage * rep~ measure, value.var=\"spearman\")\n",
    "#cdiff = ddply(cdiff, .(coverage, rep), summarise, spearman_d=wip - ip)\n",
    "cdiff = ddply(cdiff, .(coverage), summarise, diff_m=mean(wip - ip), diff_sd=sd(wip - ip))\n",
    "\n",
    "summary(cdiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggplot(cdiff, aes(x=coverage, y=diff_m, ymin=diff_m-diff_sd, ymax=diff_m+diff_sd)) +\n",
    "    geom_line() +\n",
    "    geom_ribbon(alpha=0.4) +\n",
    "    xlab('Genome Coverage') +\n",
    "    ylab(expression(paste(\"Spearman's \", rho))) +\n",
    "    #scale_x_log10()+\n",
    "    theme_bw() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale vs $\\rho$\n",
    "---------------\n",
    "\n",
    "Like coverage, we investigate the effect of variation at a constant coverage, in this case 30x. I also convert the scale into its inverse, as this is how some people prefer to think of it (i.e. one variant in X bases, as opposed to 0.0x variants per base on average. Each to their own...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale = stats[stats$coverage==30 & stats$scale <= 0.01,]\n",
    "scale$var = as.factor(as.character(1/scale$scale))\n",
    "scale$var = reorder(scale$var, 1/scale$scale, min)\n",
    "scale$scale = 1/scale$scale\n",
    "str(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssumm = ddply(scale, .(measure, scale), summarise,\n",
    "              sp_avg=mean(spearman),\n",
    "              sp_max=(mean(spearman) + sd(spearman)),\n",
    "              sp_min=(mean(spearman) - sd(spearman)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = ggplot(ssumm, aes(x=scale,  y=sp_avg, ymin=sp_min, ymax=sp_max, group=measure)) +\n",
    "    geom_line(aes(linetype=measure)) +\n",
    "    geom_ribbon(aes(fill=measure), alpha=0.2) +\n",
    "    xlab('Divergence (1 variant per x bases)') +\n",
    "    ylab(expression(paste(\"Spearman's \", rho))) +\n",
    "    #scale_x_log10() +\n",
    "    scale_x_reverse() +\n",
    "    theme_bw()\n",
    "pdf(\"variation_vs_accuracy.pdf\")\n",
    "print(p)\n",
    "dev.off()\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conclusions\n",
    "-----------\n",
    "\n",
    "- I think there might be an issue with the way I normalise trees. I think that we are probably at a higher level of divergence than I expect if we use the mean. I will do a run with a couple of reps using the maximum distance set to 1.0, i.e. that the entire tree scale is 0.5 (from root to tip, and then back again =1.0).\n",
    "- I'd like to re-do the coverage sweep at a scale of 0.005 or 0.002 or even 0.001. I think that this might be more inline with our rice experiment. My take home from this is that WIP is only important when your signal:noise ratio is low, like when you have a small amount of variation. Otherwise, they are equivalent (neither is signficantly worse on average). Norman, can you comment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
