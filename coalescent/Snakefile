# Mapping of population name: divergence
from string import ascii_uppercase
import itertools as itl
from math import log, ceil
from snakemake.utils import format as snakefmt
import random
import re
import json

random.seed(int(config['seed']))

N = config["population_size"]
COV_VAR = [(d['cov'], d['var']) for d in config["coverage_variablity"]]


#SEEDS = list(random.sample(range(10000), int(config["num_replicates"])))
SEEDS = set()
while len(SEEDS) < int(config["num_replicates"]):
    SEEDS.add(random.randrange(1e4))
SEEDS = list(SEEDS)
print(SEEDS)

# Sample names
labels = ["".join(x)
          for x in itl.product(ascii_uppercase, repeat=int(ceil(log(N, 26))))]

GENOMES = [labels[i] for i in range(N)]
SAMPLES = [str(i+1) for i in range(config['runs_per_sample'])]


# All sim params
READ_NUMS = {}
SCALES = set()
for seed in SEEDS:
    random.seed(int(seed))
    readnum = {}
    for g in GENOMES:
        readnum[g] = {}
        for s in SAMPLES:
            readnum[g][str(s)] = {}
            for c, v in COV_VAR:
                cov = random.gauss(c, c * float(config["coverage_cv"]))
                nread = max((cov * config["genome_size"]) / 200, 100)
                try:
                    readnum[g][str(s)][str(c)][str(v)] = int(nread)
                except KeyError:
                    readnum[g][str(s)][str(c)] = {str(v): int(nread)}
                SCALES.add(v)
    READ_NUMS[str(seed)] = readnum
SCALES = list(SCALES)

METRICS = ['wip', 'ip']


def mash_res(wc):
    if config["mash"]:
        return expand(expand("data/{{seed}}/mash/{cov}x-{scale}.mashdist", zip,
                             cov=map(lambda x: x[0], COV_VAR),
                             scale=map(lambda x: x[1], COV_VAR)),
                      seed=SEEDS)
    else:
        return []

def kwip_res(wc):
    if config.get('kwip', False):
        return (
              expand(expand("data/{{seed}}/kwip/{{sketch_size}}sz/{cov}x-{scale}.stat", zip,
                            cov=map(lambda x: x[0], COV_VAR),
                            scale=map(lambda x: x[1], COV_VAR)),
                     sketch_size=config["sketch_sizes"], seed=SEEDS)
               + expand(expand("data/{{seed}}/kwip/{{sketch_size}}sz/{cov}x-{scale}-{{metric}}.{{ext}}", zip,
                               cov=map(lambda x: x[0], COV_VAR),
                               scale=map(lambda x: x[1], COV_VAR)),
                        sketch_size=config["sketch_sizes"], seed=SEEDS, metric=METRICS, ext=['dist', 'kern'])
        )
    return []

def reads_res(wc):
    if config.get('keep_reads', False):
        return expand(expand("data/{{seed}}/reads/{cov}x-{scale}/{{genome}}-{{sample}}_il.fastq.gz", zip,
                             cov=map(lambda x: x[0], COV_VAR),
                             scale=map(lambda x: x[1], COV_VAR)),
                      seed=SEEDS, genome=GENOMES, sample=SAMPLES)
    return []
 

rule all:
    input:
        expand("data/{seed}/all_genomes-{scale}.dist", seed=SEEDS, scale=SCALES),
        reads_res,
        mash_res,
        kwip_res,
        "data/stats/rho.tab",

rule clean:
    shell:
        "rm -rf data .snakemake"


def scrm_args(wc):
    args = "{:d} {:d} ".format(config['population_size'], config['num_chroms'])
    #args += "-r {:d} {:d} ".format(Ne * Nrecomb, config['genome_size'])
    args += "-T "
    return args

rule population:
    output:
        "data/{seed}/population_prescale.nwk"
    params:
        args=scrm_args,
        seed=lambda w: w.seed,
    log:
        "data/{seed}/log/scrm.log"
    shell:
        "scrm"
        " {params.args}"
        " -seed {params.seed}"
        " 2>&1"
        "| tee {log} | grep '(' "  # Grep for (, which are only in a newick tree output line
        " >{output}"


rule scaletree:
    input:
        "data/{seed}/population_prescale.nwk"
    output:
        "data/{seed}/population.nwk"
    log:
        "data/{seed}/log/scaletree.log"
    shell:
        "scripts/scaletree.py"
        " {input}"
        " >{output}"
        " 2>{log}"


rule paramfile:
    input:
        "data/{seed}/population.nwk"
    output:
        "data/{seed}/dawg-{scale}.params",
    params:
        scale=lambda wc: wc.scale
    run:
        dawg = '''
        [Tree]
        Scale = {scale}
        [Indel]
        Model.Ins = Geo
        Model.Del = Geo
        Rate.Ins = 0.005
        Rate.Del = 0.005

        [Subst]
        Model = F84
        Freqs  = 0.3, 0.2, 0.2, 0.3
        Params = 2.5
        '''.format(scale=params.scale)
        with open(input[0])  as fh:
            for i, treeline in enumerate(fh):
                m = re.search(r'\[(.*)\](\(.*;)', treeline)
                if m:
                    length, tree = m.groups()
                else:
                    length = str(config['genome_size'])
                    tree = treeline
                dawg += '''
                [[-]]
                Root.Segment = {i:d}
                Root.Length = {length}
                Tree.Tree = {tree}
                '''.format(i=i, length=length, tree=tree)
        dawg = '\n'.join(x.lstrip() for x in dawg.split('\n'))
        with open(output[0], 'w') as fh:
            print(dawg, file=fh)


rule all_genomes:
    input:
        "data/{seed}/dawg-{scale}.params",
    output:
        "data/{seed}/all_genomes-{scale}.fasta"
    log:
        "data/{seed}/log/seqgen-{scale}.log"
    params:
        seed=lambda w: w.seed,
    shell:
        'dawg2'
        ' -o {output}'
        ' --seed {params.seed}'
        ' {input}'
        ' 2>{log} 1>&2'


rule alndist:
    input:
        "data/{seed}/all_genomes-{scale}.fasta"
    output:
        "data/{seed}/all_genomes-{scale}.dist"
    log:
        "data/{seed}/log/alndist-{scale}.log"
    shell:
        'scripts/alndist.py'
        ' {input}'
        ' 2>{log} 1>&2'


rule genomes:
    input:
        "data/{seed}/all_genomes-{scale}.fasta"
    output:
        expand("data/{{seed}}/genomes/{{scale}}/{g}.fasta", g=GENOMES)
    params:
        dir="data/{seed}/genomes/{scale}/",
    log:
        "data/{seed}/log/splitfa-{scale}.log"
    shell:
        "scripts/splitfa.py"
        " {input}"
        " {params.dir}"
        " >{log} 2>&1"


rule samples:
    input:
        "data/{seed}/genomes/{scale}/{genome}.fasta",
    output:
        r1=temp("data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R1.fastq"),
        r2=temp("data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R2.fastq"),
    params:
        rn=lambda w: str(READ_NUMS[w.seed][w.genome][w.sample][w.cov][w.scale]),
        seed=lambda w: w.seed,
    log:
        "data/{seed}/log/samples/{cov}x-{scale}/{genome}-{sample}.log"
    threads:
        1
    shell:
        "mason_simulator"
        " -ir {input}"
        " --illumina-read-length 101"
        " -o {output.r1}"
        " -or {output.r2}"
        " --seed {params.seed}"
        " -n {params.rn}"
        " --num-threads {threads}"
        " >{log} 2>&1"


rule ilfq:
    input:
        r1="data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R1.fastq",
        r2="data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R2.fastq"
    output:
        "data/{seed}/reads/{cov}x-{scale}/{genome}-{sample}_il.fastq.gz" if config.get("keep_reads", False)
         else temp("data/{seed}/reads/{cov}x-{scale}/{genome}-{sample}_il.fastq.gz")
    log:
        "data/{seed}/log/join/{cov}x-{scale}/{genome}-{sample}.log"
    shell:
        "(pairs join -ts"
        "   {input.r1}"
        "   {input.r2}"
        "| gzip > {output}"
        ") 2>>{log}"


rule hash:
    input:
        r1="data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R1.fastq",
        r2="data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R2.fastq"
    output:
        temp("data/{seed}/sketches/{sketch_size}sz-{cov}x-{scale}/{genome}-{sample}.ct.gz"),
    params:
        x=lambda wc: wc.sketch_size,
        N='1',
        k='20',
    log:
        "data/{seed}/log/sketches/{sketch_size}sz-{genome}-{sample}_{cov}x.log"
    threads:
        1
    shell:
        "load-into-counting.py"
        " -N {params.N}"
        " -x {params.x}"
        " -k {params.k}"
        " -b"
        " -s tsv"
        " -T {threads}"
        " {output}"
        " {input}"
        " >{log} 2>&1"

rule mash:
    input:
        expand("data/{{seed}}/reads/{{cov}}x-{{scale}}/{genome}-{sample}_il.fastq.gz",
               genome=GENOMES, sample=SAMPLES),
    output:
        sketch=temp("data/{seed}/mash/{cov}x-{scale}_allsketch.msh"),
        dist="data/{seed}/mash/{cov}x-{scale}.mashdist",
    log:
        "data/{seed}/log/mash/{cov}x-{scale}.log"
    threads:
        1
    shell:
        "(mash sketch -o {output.sketch} {input} &&"
        " mash dist {output.sketch} {input} |"
        " ./scripts/mash2kwipdist.py /dev/stdin >{output.dist}"
        ") >{log} 2>&1"


rule kwip:
    input:
        expand("data/{{seed}}/sketches/{{sketch_size}}sz-{{cov}}x-{{scale}}/{genome}-{sample}.ct.gz",
               genome=GENOMES, sample=SAMPLES),
    output:
        d="data/{seed}/kwip/{sketch_size}sz/{cov}x-{scale}-{metric}.dist",
        k="data/{seed}/kwip/{sketch_size}sz/{cov}x-{scale}-{metric}.kern"
    params:
        metric= lambda w: '-U' if w.metric == 'ip' else '',
    log:
        "data/{seed}/log/kwip/{sketch_size}sz-{cov}x-{scale}-{metric}.log"
    threads:
        1
    shell:
        "kwip"
        " {params.metric}"
        " -d {output.d}"
        " -k {output.k}"
        " -t {threads}"
        " {input}"
        " >{log} 2>&1"

rule kwip_stats:
    input:
        expand("data/{{seed}}/sketches/{{sketch_size}}sz-{{cov}}x-{{scale}}/{genome}-{sample}.ct.gz",
               genome=GENOMES, sample=SAMPLES),
    output:
        "data/{seed}/kwip/{sketch_size}sz/{cov}x-{scale}.stat"
    log:
        "data/{seed}/log/kwip-stats/{sketch_size}sz-{cov}x-{scale}.log"
    threads:
        1
    shell:
        "kwip-stats"
        " -o {output}"
        " -t {threads}"
        " {input}"
        " >{log} 2>&1"

rule kwip_rho:
    input:
        truth="data/{seed}/all_genomes-{scale}.dist",
        obtained="data/{seed}/kwip/{sketch_size}sz/{cov}x-{scale}-{metric}.dist",
    output:
        temp("data/{seed}/stats/rho/{metric}_{sketch_size}sz_{cov}x_{scale}.tab")
    log:
        "data/{seed}/log/stats_rho_{metric}_{sketch_size}sz_{cov}x_{scale}.log"
    threads:
        1
    params:
        reps=config['runs_per_sample'],
    shell:
        " scripts/calc_rho.py"
        " -S {wildcards.seed}"
        " -m {wildcards.metric}"
        " -s {wildcards.sketch_size}"
        " -c {wildcards.cov}"
        " -v {wildcards.scale}"
        " -r {params.reps}"
        " {input.truth}"
        " {input.obtained}"
        " >{output}"
        " 2>{log}"

rule mash_rho:
    input:
        "data/{seed}/all_genomes-{scale}.dist",
        "data/{seed}/mash/{cov}x-{scale}.mashdist",
    output:
        "data/{seed}/stats/rho/mash_{cov}x_{scale}.tab"
    log:
        "data/{seed}/log/stats_rho_mash_{cov}x_{scale}.log"
    threads:
        1
    params:
        reps=config['runs_per_sample'],
    shell:
        " scripts/calc_rho.py"
        " -S {wildcards.seed}"
        " -m mash"
        " -s NA"
        " -c {wildcards.cov}"
        " -v {wildcards.scale}"
        " -r {params.reps}"
        " {input}"
        " >{output}"
        " 2>{log}"



def combined_input(wc):
    inputs = []
    pathfmt = "data/{seed}/stats/rho/{metric}_{sketch_size}sz_{cov}x_{scale}.tab"
    if config.get('kwip', True):
        for seed in SEEDS:
            for cov, scale in COV_VAR:
                for sketch_size in config["sketch_sizes"]:
                    for metric in METRICS:
                        inputs.append(pathfmt.format(seed=seed, metric=metric,
                                                    sketch_size=sketch_size, cov=cov,
                                                    scale=scale))
    if config["mash"]:
        pathfmt = "data/{seed}/stats/rho/mash_{cov}x_{scale}.tab"
        for seed in SEEDS:
            for cov, scale in COV_VAR:
                inputs.append(pathfmt.format(seed=seed, cov=cov, scale=scale))
    return inputs

rule combined_rho:
    input:
       combined_input
    output:
        "data/stats/rho.tab"
    shell:
        "cat {input} > {output}"
