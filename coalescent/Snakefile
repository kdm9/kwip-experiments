# Mapping of population name: divergence
from string import ascii_uppercase
import itertools as itl
from math import log, ceil
from snakemake.utils import format as snakefmt
import random
import re
import json

NEXP = 50   # number of reps
Ne = 12     # Effective population size
Nrecomb = 1 # Recombinations per generatiton per haplotype
Nloci = 1   # Chromosomes
N = Ne      # number of samples from population
REPS = 3    # Replicate runs per sample
COVERAGE_CV = 0.01
GENOME_SIZE = int(1e6)
HASH_SIZE = "5e8"
# Tuples of coverage, tree scale (variants per base from root to tip)
COV_VAR = [
# Range of coverages
    (0.5, 0.001),
    (1, 0.001),
    (2, 0.001),
    (4, 0.001),
    (8, 0.001),
    (12, 0.001),
    (15, 0.001),
    (30, 0.001),
    (50, 0.001),
    (100, 0.001),
    (200, 0.001),


#    (0.5, 0.01),
#    (1, 0.01),
#    (2, 0.01),
#    (4, 0.01),
#    (8, 0.01),
#    (12, 0.01),
#    (15, 0.01),
#    (30, 0.01),
#    (50, 0.01),

# Range of scales
    (10, 0.1),
    (10, 0.06),
    (10, 0.04),
    (10, 0.02),
    (10, 0.01),
    (10, 0.006),
    (10, 0.004),
    (10, 0.002),
    (10, 0.001),
]
#DISABLED: Npop = 4    # populations
random.seed(3301)

SEEDS = set()
while len(SEEDS) < NEXP:
    SEEDS.add(random.randrange(1e4))
SEEDS = list(SEEDS)
print(SEEDS)

# Sample names
labels = ["".join(x)
          for x in itl.product(ascii_uppercase, repeat=int(ceil(log(N, 26))))]

GENOMES = [labels[i] for i in range(N)]
SAMPLES = [str(i+1) for i in range(REPS)]


# All sim params
READ_NUMS = {}
SCALES = set()
for seed in SEEDS:
    random.seed(seed)
    readnum = {}
    for g in GENOMES:
        readnum[g] = {}
        for s in SAMPLES:
            readnum[g][str(s)] = {}
            for c, v in COV_VAR:
                cov = random.gauss(c, c * COVERAGE_CV)
                nread = max((cov * GENOME_SIZE) / 200, 100)
                try:
                    readnum[g][str(s)][str(c)][str(v)] = int(nread)
                except KeyError:
                    readnum[g][str(s)][str(c)] = {str(v): int(nread)}
                SCALES.add(v)
    READ_NUMS[str(seed)] = readnum
SCALES = list(SCALES)

METRICS = ['wip', 'ip']


rule all:
    input:
        expand("data/{seed}/all_genomes-{scale}.dist", seed=SEEDS, scale=SCALES),
        expand(expand("data/{{seed}}/kwip/{cov}x-{scale}.stat", zip,
                      cov=map(lambda x: x[0], COV_VAR),
                      scale=map(lambda x: x[1], COV_VAR)),
               seed=SEEDS),
        expand(expand("data/{{seed}}/kwip/{cov}x-{scale}-{{metric}}.{{ext}}", zip,
                      cov=map(lambda x: x[0], COV_VAR),
                      scale=map(lambda x: x[1], COV_VAR)),
               seed=SEEDS, metric=METRICS, ext=['dist', 'kern']),
        expand(expand("data/{{seed}}/kwip/{cov}x-{scale}.stat", zip,
                      cov=map(lambda x: x[0], COV_VAR),
                      scale=map(lambda x: x[1], COV_VAR)),
               seed=SEEDS),


rule clean:
    shell:
        "rm -rf data .snakemake"


def scrm_args(wc):
    args = "{:d} {:d} ".format(Ne, Nloci)
    #args += "-r {:d} {:d} ".format(Ne * Nrecomb, GENOME_SIZE)
    args += "-T "
    return args

rule population:
    output:
        "data/{seed}/population_prescale.nwk"
    params:
        args=scrm_args,
        seed=lambda w: w.seed,
    log:
        "data/{seed}/log/scrm.log"
    shell:
        "scrm"
        " {params.args}"
        " -seed {params.seed}"
        " 2>&1"
        "| tee {log} | grep '(' "  # Grep for (, which are only in a newick tree output line
        " >{output}"


rule scaletree:
    input:
        "data/{seed}/population_prescale.nwk"
    output:
        "data/{seed}/population.nwk"
    log:
        "data/{seed}/log/scaletree.log"
    shell:
        "scripts/scaletree.py"
        " {input}"
        " >{output}"
        " 2>{log}"


rule paramfile:
    input:
        "data/{seed}/population.nwk"
    output:
        "data/{seed}/dawg-{scale}.params",
    params:
        scale=lambda wc: wc.scale
    run:
        dawg = '''
        [Tree]
        Scale = {scale}
        [Indel]
        Model.Ins = Geo
        Model.Del = Geo
        Rate.Ins = 0.005
        Rate.Del = 0.005

        [Subst]
        Model = F84
        Freqs  = 0.3, 0.2, 0.2, 0.3
        Params = 2.5
        '''.format(scale=params.scale)
        with open(input[0])  as fh:
            for i, treeline in enumerate(fh):
                m = re.search(r'\[(.*)\](\(.*;)', treeline)
                if m:
                    length, tree = m.groups()
                else:
                    length = str(GENOME_SIZE)
                    tree = treeline
                dawg += '''
                [[-]]
                Root.Segment = {i:d}
                Root.Length = {length}
                Tree.Tree = {tree}
                '''.format(i=i, length=length, tree=tree)
        dawg = '\n'.join(x.lstrip() for x in dawg.split('\n'))
        with open(output[0], 'w') as fh:
            print(dawg, file=fh)


rule all_genomes:
    input:
        "data/{seed}/dawg-{scale}.params",
    output:
        "data/{seed}/all_genomes-{scale}.fasta"
    log:
        "data/{seed}/log/seqgen-{scale}.log"
    params:
        seed=lambda w: w.seed,
    shell:
        'dawg2'
        ' -o {output}'
        ' --seed {params.seed}'
        ' {input}'
        ' 2>{log} 1>&2'


rule alndist:
    input:
        "data/{seed}/all_genomes-{scale}.fasta"
    output:
        "data/{seed}/all_genomes-{scale}.dist"
    log:
        "data/{seed}/log/alndist-{scale}.log"
    shell:
        'scripts/alndist.py'
        ' {input}'
        ' 2>{log} 1>&2'


rule genomes:
    input:
        "data/{seed}/all_genomes-{scale}.fasta"
    output:
        expand("data/{{seed}}/genomes/{{scale}}/{g}.fasta", g=GENOMES)
    params:
        dir="data/{seed}/genomes/{scale}/",
    log:
        "data/{seed}/log/splitfa-{scale}.log"
    shell:
        "scripts/splitfa.py"
        " {input}"
        " {params.dir}"
        " >{log} 2>&1"


rule samples:
    input:
        "data/{seed}/genomes/{scale}/{genome}.fasta",
    output:
        r1=temp("data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R1.fastq"),
        r2=temp("data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R2.fastq"),
    params:
        rn=lambda w: str(READ_NUMS[w.seed][w.genome][w.sample][w.cov][w.scale]),
        seed=lambda w: w.seed,
    log:
        "data/{seed}/log/samples/{cov}x-{scale}/{genome}-{sample}.log"
    threads:
        1
    shell:
        "mason_simulator"
        " -ir {input}"
        " --illumina-read-length 101"
        " -o {output.r1}"
        " -or {output.r2}"
        " --seed {params.seed}"
        " -n {params.rn}"
        " --num-threads {threads}"
        " >{log} 2>&1"


rule ilfq:
    input:
        r1="data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R1.fastq",
        r2="data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R2.fastq"
    output:
        temp("data/{seed}/reads/{cov}x-{scale}/{genome}-{sample}_il.fastq.gz")
    log:
        "data/{seed}/log/join/{cov}x-{scale}/{genome}-{sample}.log"
    shell:
        "interleave-reads.py"
        " {input.r1}"
        " {input.r2}"
        " 2>>{log}"
        " > {output}"
#        " | trimit"
#        " -q 28"
#        " 2>/dev/null"
#        " | gzip --fast"


rule hash:
    input:
        r1="data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R1.fastq",
        r2="data/{seed}/temp/{cov}x-{scale}/{genome}-{sample}_R2.fastq"
    output:
        temp("data/{seed}/hashes/{cov}x-{scale}/{genome}-{sample}.ct.gz"),
    params:
        x=HASH_SIZE,
        N='1',
        k='20',
    log:
        "data/{seed}/log/hashes/{genome}-{sample}_{cov}x.log"
    threads:
        1
    shell:
        "load-into-counting.py"
        " -N {params.N}"
        " -x {params.x}"
        " -k {params.k}"
        " -b"
        " -s tsv"
        " -T {threads}"
        " {output}"
        " {input}"
        " >{log} 2>&1"


rule kwip:
    input:
        expand("data/{{seed}}/hashes/{{cov}}x-{{scale}}/{genome}-{sample}.ct.gz",
               genome=GENOMES, sample=SAMPLES),
    output:
        d="data/{seed}/kwip/{cov}x-{scale}-{metric}.dist",
        k="data/{seed}/kwip/{cov}x-{scale}-{metric}.kern"
    params:
        metric= lambda w: '-U' if w.metric == 'ip' else '',
    log:
        "data/{seed}/log/kwip/{cov}x-{scale}-{metric}.log"
    threads:
        1
    shell:
        "kwip"
        " {params.metric}"
        " -d {output.d}"
        " -k {output.k}"
        " -t {threads}"
        " {input}"
        " >{log} 2>&1"


rule kwip_stats:
    input:
        expand("data/{{seed}}/hashes/{{cov}}x-{{scale}}/{genome}-{sample}.ct.gz",
               genome=GENOMES, sample=SAMPLES),
    output:
        "data/{seed}/kwip/{cov}x-{scale}.stat"
    log:
        "data/{seed}/log/kwip-stats/{cov}x-{scale}.log"
    threads:
        1
    shell:
        "kwip-stats"
        " -o {output}"
        " -t {threads}"
        " {input}"
        " >{log} 2>&1"
