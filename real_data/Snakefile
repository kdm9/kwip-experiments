HASH_SIZE = "5e9"
METRICS = ['wip', 'ip']
SETS = config


# No user serviceable bits below here
ALLSAMPLES = set()
for setname, runs in SETS.items():
    for r in runs:
        ALLSAMPLES.add(r)
ALLSAMPLES = list(ALLSAMPLES)


## BEGIN RULES
rule all:
    input:
        expand("data/kwip/{set}_{metric}.{mat}", set=SETS.keys(), metric=METRICS, mat=["dist", "kern"]),

rule clean:
    shell:
        "rm -rf data .snakemake"

rule sra:
    output:
        "data/sra/{run}.sra",
    log:
        "data/log/getrun/{run}.log"
    params:
        srr=lambda w: w.run
    shell:
        "get-run.py"
        "   -d data/sra"
        "   -s "
        "   -i {wildcards.run}"
        " >{log} 2>&1"

rule reads:
    input:
        "data/sra/{run}.sra",
    output:
        temp("data/tmp/reads/{run}_raw_il.fastq")
    log:
        "data/log/reads/{run}.log"
    shell:
        "fastq-dump"
        "   --split-spot"
        "   --skip-technical"
        "   --stdout"
        "   --readids"
        "   --defline-seq '@$sn/$ri'"
        "   --defline-qual '+'"
        "   {input}"
        " >{output}"
        " 2>{log}"

rule sickle:
    input:
        "data/tmp/reads/{run}_raw_il.fastq"
    output:
        temp("data/tmp/reads_trimmed/{run}_il.fastq"),
    log:
        "data/log/sickle/{run}.log"
    shell:
        "sickle se"
        "   -t sanger"
        "   -q 28"
        "   -l 1"  # Keep all reads
        "   -f {input}"
        "   -o {output}"
        " 2>{log} >&2"


rule trimitreads:
    input:
        "data/tmp/reads/{run}_raw_il.fastq"
    output:
        r="data/reads/{run}_qc_il.fastq.gz",
        yml="data/qc_reports/{run}.yml",
    log:
        "data/log/qcreads/{run}.log"
    shell:
        "( trimit"
        "   -y {output.yml}"
        "   -q 28"
        "   {input}"
        " | gzip --fast > {output.r})"
        " 2>{log}"


rule hash:
    input:
        "data/tmp/reads_trimmed/{run}_il.fastq"
    output:
        "data/counts/{run}.ct.gz"
    params:
        x=HASH_SIZE,
        N='1',
        k='20',
    threads:
        4
    log:
        "data/log/counts/{run}.log"
    shell:
        "load-into-counting.py"
        "   -N {params.N}"
        "   -x {params.x}"
        "   -k {params.k}"
        "   -T {threads}"
        "   -b"
        "   -s tsv"
        "   {output}"
        "   {input}"
        "   >{log} 2>&1"


rule kwip:
    input:
        lambda wc: expand("data/counts/{run}.ct.gz", run=SETS[wc.set])
    output:
        d="data/kwip/{set}_{metric}.dist",
        k="data/kwip/{set}_{metric}.kern"
    params:
        metric=lambda w: '-U' if w.metric == 'ip' else '',
    log:
        "data/log/kwip/{set}-{metric}.log"
    threads:
        16
    shell:
        "kwip"
        " {params.metric}"
        " -d {output.d}"
        " -k {output.k}"
        " -t {threads}"
        " {input}"
        " >{log} 2>&1"


rule kwip_stats:
    input:
        lambda wc: expand("data/counts/{run}.ct.gz", run=SETS[wc.set])
    output:
        "data/kwip/{set}.stat"
    log:
        "data/log/kwip-stats/{set}.log"
    threads:
        16
    shell:
        "kwip-stats"
        " -o {output}"
        " -t {threads}"
        " {input}"
        " >{log} 2>&1"
